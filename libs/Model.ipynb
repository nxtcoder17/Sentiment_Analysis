{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scikit-Learn ML Classifier Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Custom Module: XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "## MultiLayer Perceptron Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from review import Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model (Review):\n",
    "    def __init__ (self, X=None, y=None, debug=False, model = None):\n",
    "        \"\"\" \n",
    "        X: the actual text of review\n",
    "        y: the sentiment score either positive or negative\n",
    "        model: should be a function object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model()\n",
    "        self.model_name = model.__name__\n",
    "        pickle_path = Path (f\"{self.model_name}-trained_data.pickle\")\n",
    "        if not debug and Path.exists (pickle_path):\n",
    "            self.vectorizer, self.X_train,self.X_test, self.y_train, self.y_test = pickle.load (open(pickle_path, \"rb\"))\n",
    "        else:\n",
    "            assert X is not None and y is not None, \"Dataset X and y can't be EMPTY\"\n",
    "            processed_X = list(' '.join (self.pre_process(x)) for x in X)\n",
    "            self.vectorizer = TfidfVectorizer(vocabulary = list(self.features))\n",
    "            processed_X = self.vectorizer.fit_transform (processed_X)\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split (processed_X, y, random_state=7, test_size=0.2)\n",
    "\n",
    "            data = (self.vectorizer, self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "            pickle.dump(data, open (pickle_path, \"wb\"))\n",
    "            \n",
    "    def train (self):\n",
    "        self.model.fit (self.X_train, self.y_train)\n",
    "        predicted = self.model.predict (self.X_test)\n",
    "        self.accuracy = accuracy_score (self.y_test, predicted)\n",
    "        print (f\"Accuracy of {self.model_name} Model: {self.accuracy}\")\n",
    "        print (f\"Confusion Matrix for {self.model_name} Model: \")\n",
    "        print (confusion_matrix (self.y_test, predicted))\n",
    "        \n",
    "    def predict (self, msg):\n",
    "        if not isinstance (msg, pd.Series):\n",
    "            msg = pd.Series ([msg])\n",
    "        msg = self.vectorizer.transform (msg)\n",
    "        return self.model.predict (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB Model\n",
    "class NaiveBayes_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__(model = MultinomialNB, debug=debug, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier Model\n",
    "class RandomForestClassifier_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__(model = RandomForestClassifier, debug=debug, X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Model\n",
    "class DecisionTreeClassifier_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__(model=DecisionTreeClassifier, debug=debug, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Classifier Model\n",
    "class SVC_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__ (model = SVC, debug=debug, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Classifier Model\n",
    "class KNeighborsClassifier_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__ (model = KNeighborsClassifier, debug=debug, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Layer Perceptron Model\n",
    "class MLPClassifier_Model (Base_Model):\n",
    "    def __init__ (self, X=None, y = None, debug=False):\n",
    "        super().__init__(model = MLPClassifier, debug=debug, X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was pleasantly surprised on my first visit not very long ago & now I have already visited about a dozen times & am taking friends who did not know about the place.\n",
      "The food in this restaurant is definitely something to write home about. It's fresh, almost akin to fine dining at half the price. I believe the best place to dine out after Jaypee Greens in Greater Noida.\n",
      "    \n",
      "{'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'compound': 0.9603}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def trial():\n",
    "        df = pd.read_csv (\"../datasets/Restaurant_Reviews.tsv\", sep='\\t')\n",
    "        print (df.head())\n",
    "        X = df.loc[:]['Review']\n",
    "        y = df.loc[:]['Liked']\n",
    "\n",
    "        print (X.head())\n",
    "        print (y.head())\n",
    "\n",
    "        rfm = RandomForestClassifier_Model(X=X, y = y, debug=False)\n",
    "        rfm.train()\n",
    "\n",
    "        mlpc = MLPClassifier_Model()\n",
    "        mlpc.model.max_iter = 1000\n",
    "        mlpc.train()\n",
    "        \n",
    "        nb = NaiveBayes_Mode(X=X, y=y, debug=False)\n",
    "        nb.train()\n",
    "        \n",
    "        msg = \"I did not like the food.\"\n",
    "        print(msg, mlpc.predict(msg))\n",
    "        print(msg, nb.predict(msg))\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        msg = \"Food was good but service was not good.\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "        msg = \"Food was amazing. Must go\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "        msg = \"Waste of Money\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "        msg = \"Kind of liked the pizza, but starters were the speciality.\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "        msg = \"\"\"The Tikkas and kebabs are wonderful. Special mention to the Fish Kaali mirch and Hazarvi Tikka. The Chicken Biryani as they say is the best in Town. They have a small diner as well as Delivery service which delivers anywhere within 15kms. The Deluxe Non Veg Thali with Butter Chicken and Paratha is also worthJ \"\"\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "        msg = \"horrible service visited last evening for a family dinner around 8.45 PM which time the place was almost vacant.   the service was so horrible and poor that had to shout on the waiters and service team. had to wait for finger bowls for almost 25 min even after which these were not circulated. After repeated requests bill was produced after almost 20 min  in all total waiting post dinner was around 40 min. card machine was not working and had to pay via Paytm.  it was a worst experience and first and last visit.\"\n",
    "        print (msg, mlpc.predict (msg))\n",
    "    \n",
    "    msg = \"\"\"I was pleasantly surprised on my first visit not very long ago & now I have already visited about a dozen times & am taking friends who did not know about the place.\n",
    "The food in this restaurant is definitely something to write home about. It's fresh, almost akin to fine dining at half the price. I believe the best place to dine out after Jaypee Greens in Greater Noida.\n",
    "    \"\"\"\n",
    "    \n",
    "    import nltk\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    print (msg)\n",
    "    print (sia.polarity_scores(msg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n",
      "0                             Wow... Loved this place.\n",
      "1                                   Crust is not good.\n",
      "2            Not tasty and the texture was just nasty.\n",
      "3    Stopped by during the late May bank holiday of...\n",
      "4    The selection on the menu was great and so wer...\n",
      "Name: Review, dtype: object\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: Liked, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balor/.local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier Model: 0.78\n",
      "Confusion Matrix for RandomForestClassifier Model: \n",
      "[[102   7]\n",
      " [ 37  54]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dataset X and y can't be EMPTY",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98c39bc0c7e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c14d616444e6>\u001b[0m in \u001b[0;36mtrial\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmlpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mmlpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmlpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-12383a4f0215>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, debug)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMLPClassifier_Model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBase_Model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b82c0b49b4b3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, debug, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset X and y can't be EMPTY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mprocessed_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset X and y can't be EMPTY"
     ]
    }
   ],
   "source": [
    "trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
