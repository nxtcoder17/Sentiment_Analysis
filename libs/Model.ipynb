{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scikit-Learn ML Classifier Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Custom Module: XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "## MultiLayer Perceptron Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from review import Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model (Review):\n",
    "    def __init__ (self, X=None, y=None, debug=False, model = None):\n",
    "        \"\"\" \n",
    "        X: the actual text of review\n",
    "        y: the sentiment score either positive or negative\n",
    "        model: should be a function object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model()\n",
    "        self.model_name = model.__name__\n",
    "        pickle_path = Path (\"Base_Model-data.pickle\")\n",
    "        if not debug and Path.exists (pickle_path):\n",
    "            self.vectorizer, self.X_train,self.X_test, self.y_train, self.y_test = pickle.load (open(pickle_path, \"rb\"))\n",
    "        else:\n",
    "            assert X is not None and y is not None, \"Dataset X and y can't be EMPTY\"\n",
    "            processed_X = list(' '.join (self.pre_process(x)) for x in X)\n",
    "            self.vectorizer = TfidfVectorizer(vocabulary = list(self.features))\n",
    "            processed_X = self.vectorizer.fit_transform (processed_X)\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split (processed_X, y, random_state=7, test_size=0.2)\n",
    "            \n",
    "            data = (self.vectorizer, self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "            pickle.dump(data, open (pickle_path, \"wb\"))\n",
    "            \n",
    "    def train (self, model):\n",
    "        self.model.fit (self.X_train, self.y_train)\n",
    "        predicted = self.model.predict (self.X_test)\n",
    "        self.accuracy = accuracy_score (self.y_test, predicted)\n",
    "        print (f\"Accuracy of {self.model_name} Model: {self.accuracy}\")\n",
    "        print (f\"Confusion Matrix for {self.model_name} Model: \")\n",
    "        print (confusion_matrix (self.y_test, predicted))\n",
    "        \n",
    "    def predict (self, msg):\n",
    "        if not isinstance (msg, pd.Series):\n",
    "            msg = pd.Series ([msg])\n",
    "        msg = self.vectorizer.transform (msg)\n",
    "        return self.model.predict (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Liked\n",
      "0                           Wow... Loved this place.      1\n",
      "1                                 Crust is not good.      0\n",
      "2          Not tasty and the texture was just nasty.      0\n",
      "3  Stopped by during the late May bank holiday of...      1\n",
      "4  The selection on the menu was great and so wer...      1\n",
      "0                             Wow... Loved this place.\n",
      "1                                   Crust is not good.\n",
      "2            Not tasty and the texture was just nasty.\n",
      "3    Stopped by during the late May bank holiday of...\n",
      "4    The selection on the menu was great and so wer...\n",
      "Name: Review, dtype: object\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "Name: Liked, dtype: int64\n",
      "Length of Feature Vector:  858\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv (\"../datasets/Restaurant_Reviews.tsv\", sep='\\t')\n",
    "print (df.head())\n",
    "X = df.loc[:]['Review']\n",
    "y = df.loc[:]['Liked']\n",
    "\n",
    "print (X.head())\n",
    "print (y.head())\n",
    "bm = Base_Model (X, y)\n",
    "print (\"Length of Feature Vector: \", len(bm.vectorizer.get_feature_names()))\n",
    "#print (bm.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    500\n",
      "0    500\n",
      "Name: Liked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To check if the dataset is actually balanced or not \n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB Model\n",
    "class NaiveBayes_Model (Base_Model):\n",
    "    def __init__ (self):\n",
    "        super().__init__(model = MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier Model\n",
    "class RandomForestClassifier_Model (Base_Model):\n",
    "    def __init__ (self):\n",
    "        super().__init__(model = RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Model\n",
    "class DecisionTreeClassifier_Model (Base_Model):\n",
    "    def __init__ (self):\n",
    "        super().__init__(model=DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Classifier Model\n",
    "class SVC_Model (Base_Model):\n",
    "    def __init__(self):\n",
    "        super().__init__ (model = SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Classifier Model\n",
    "class KNeighborsClassifier_Model (Base_Model):\n",
    "    def __init__ (self):\n",
    "        super().__init__ (model = KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Layer Perceptron Model\n",
    "class MLPClassifier_Model (Base_Model):\n",
    "    def __init__ (self):\n",
    "        super().__init__(model = MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier Model: 0.75\n",
      "Confusion Matrix for RandomForestClassifier Model: \n",
      "[[93 16]\n",
      " [34 57]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balor/.local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfm = RandomForestClassifier_Model()\n",
    "rfm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier Model: 0.755\n",
      "Confusion Matrix for MLPClassifier Model: \n",
      "[[87 22]\n",
      " [27 64]]\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier_Model()\n",
    "mlpc.model.max_iter = 1000\n",
    "mlpc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict (\"Food was not good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "features = set (nb.vectorizer.get_feature_names())\n",
    "print ('not' in features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "### Multinomial NaiveBayes Model for Sentiment Analysis Review ###\n",
    "##################################################################\n",
    "class NaiveBayes_Model (Review):\n",
    "    def __init__(self):\n",
    "        self.model = MultinomialNB()\n",
    "        self.accuracy = None\n",
    "        self.vectorizer = None\n",
    "        \n",
    "    def train(self, X=None, y=None, debug=False):\n",
    "        \"\"\"\n",
    "            X: the training data input\n",
    "            y: the correct label for the training data\n",
    "        \"\"\"\n",
    "        pickle_path = Path (\"multinomial_NB.pickle\")\n",
    "        if not debug and Path.exists (pickle_path):\n",
    "                self.vectorizer, self.model = pickle.load (open(pickle_path, \"rb\"))\n",
    "                print (\"!!! Multinomial_NB model already trained.....skipping the training\")\n",
    "                print(\"[help]: call method train() with debug=True argument\")\n",
    "                return;\n",
    "        \n",
    "        assert X is not None and y is not None, \"No data given, How do i train ? (.>_<.)\"\n",
    "        # self.vectorizer = TfidfVectorizer ()\n",
    "        # temp = self.vectorizer.fit_transform (X)\n",
    "        # features = self.vectorizer.get_feature_names()\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer (ngram_range=(1, 1))\n",
    "        # self.vectorizer = CountVectorizer (ngram_range=(1, 1))\n",
    "        X = self.vectorizer.fit_transform (X)\n",
    "        \n",
    "        # Cause i personally only want Adjectives to be my features\n",
    "        #### The following code does the same thing  as filter is doing a couple of lines below\n",
    "        \"\"\"\n",
    "        items = []\n",
    "        for f in features:\n",
    "           if (self.pos(f)[0] in (84, 100))\n",
    "               items.append (f)\n",
    "        features = items\n",
    "        \"\"\"\n",
    "        ####\n",
    "        \n",
    "        # features = list(filter(lambda a: 84 in self.pos(a) or 100 in self.pos(a), features))\n",
    "        \n",
    "        \n",
    "        #self.vectorizer = CountVectorizer (vocabulary = features, max_features=100)\n",
    "        #X = self.vectorizer.fit_transform (X)\n",
    "        self.feature_names = self.vectorizer.get_feature_names()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2, random_state=7)\n",
    "        \n",
    "        self.model.fit (X_train, y_train)\n",
    "        predicted = self.model.predict (X_test)\n",
    "        self.accuracy_score = accuracy_score (y_test, predicted)\n",
    "        print (f\"[Accuracy Score]: {self.accuracy_score}\")\n",
    "        \n",
    "        pickled_data = (self.vectorizer, self.model)\n",
    "        pickle.dump (pickled_data, open(pickle_path, \"wb\"))\n",
    "    \n",
    "    def predict(self, msg):\n",
    "        if not isinstance (msg, pd.Series):\n",
    "            msg = pd.Series ([msg])\n",
    "        msg = self.vectorizer.transform (msg)\n",
    "        return self.model.predict (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes_Model ()\n",
    "r = Review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (\"../datasets/Restaurant_Reviews.tsv\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:]['Review']\n",
    "y = df.iloc[:]['Liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Wow... Loved this place.\n",
       "1                                   Crust is not good.\n",
       "2            Not tasty and the texture was just nasty.\n",
       "3    Stopped by during the late May bank holiday of...\n",
       "4    The selection on the menu was great and so wer...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crust not good']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.pre_process (X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.pre_process (X[2])\n",
    "processed_X = list(' '.join (r.pre_process(x)) for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow ... loved place',\n",
       " 'crust not good',\n",
       " 'not tasty texture nasty',\n",
       " 'stopped late bank holiday Rick Steve recommendation loved',\n",
       " 'selection menu great prices']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n",
      "considering # Special # check # unbelievable # ignored # Eclectic # crawfish # stood # delicioso # unexperienced # dipping # Bad # help # thrilled # nicest # FREEZING # ask # bad # imagine # unwelcome # relaxed # seasonal # eaten # Nicest # handled # gave # stepped # Horrible # set # GO # Join # stomach # sliced # refried # wasted # traditional # deliver # uninspired # Main # best # Disappointing # live # dealing # affordable # giving # favorite # claimed # eggplant # reading # voted # white # expect # having # prime # count # eat # older # tip # Tasted # reasonable # fillet # review # visit # multiple # choose # thick # sick # Nice # Soggy # handmade # fluffy # sergeant # work # GREAT # loves # likes # fast # fuzzy # larger # rude # find # climbing # customer # Love # offers # frustrated # strange # awful # busy # mid # Interesting # average # looks # inflate # expensive # sample # prompt # informative # sitting # annoying # courteous # waiting # eating # told # flat # serve # orders # impressed # welcome # correct # Mexican # black # ordered # possible # bought # complete # dark # arrived # roasted # tailored # loving # terrible # use # melted # playing # special # comfortable # shall # Based # soggy # dedicated # right # extraordinary # wrapped # wave # allergy # venture # closed # complain # entire # provides # ripped # bring # reminded # light # round # making # fantastic # lukewarm # rate # chewy # including # slow # non # disappoint # sure # oven # included # fancy # Are # gets # new # judge # fabulous # small # whelm # toasted # pricey # sweet # said # talk # Eggplant # rushed # happened # boiled # says # miss # hilarious # Last # wrap # stupid # avoid # mention # sad # brought # treated # returning # overpriced # didn't # owned # found # yummy # negligent # coming # gristle # OK # Stopped # mortified # quick # Awful # Try # imaginative # revisiting # consider # brings # mean # limited # pissd # fine # awesome # attentive # similar # blows # red # flavorful # die # massive # figured # believe # spends # looking # drawing # Poor # fav # HAD # vomited # deal # dry # spicier # filling # suck # prefer # works # decided # enjoyable # got # blandest # seated # overcooked # stinks # dirty # leave # leftover # perfect # MANY # constructed # tepid # anticipated # smelled # placed # real # atrocious # Tried # plain # tender # struggle # rolled # starving # regular # second # brunch # Best # yucky # refused # refill # frozen # Frozen # judging # sucks # particular # cakes # worst # Greek # suffers # fair # disappointed # seasoning # struck # gone # working # Italian # satisfied # unprofessional # crazy # arriving # putting # spicy # Come # recommended # EXPERIENCE # greasy # drunk # recommending # skimp # contain # Favorite # walked # rotating # solidify # absolute # cooked # happy # subpar # colder # poor # saving # positive # trying # overall # maintaining # serving # generous # fried # feel # acknowledged # petty # mind # outshining # suggest # diverse # rare # Have # loved # bland # impressive # Spend # Took # let # attached # gross # relax # qualified # break # personable # redeeming # hard # clean # Veggitarian # finish # Ample # running # double # short # human # Jamaican # exceeding # Needless # lined # inspired # TOLD # crusty # rowdy # drag # ended # hooked # missed # summarize # STEP # vacant # fat # experience # known # like # checked # Awesome # golden # indicate # know # weekly # outdoor # homemade # sushi # eyed # pleased # accomodate # place # grilled # pay # talking # grow # helpful # stuffed # serves # providing # wide # English # kind # First # multi # blue # feeling # Coming # Worst # combo # driest # swung # going # enjoy # sit # excellent # tell # glad # honest # disappointing # super # polite # wasting # pretty # asked # seating # pack # huge # Bland # little # burned # waited # wrong # Point # Sooooo # trimmed # dusted # imagined # wonderful # drenched # puréed # decent # undercooked # old # healthy # killer # dining # biggest # Gave # delicate # decide # disrespected # Be # watch # covered # extensive # solid # Check # rated # big # continue # famous # delish # privileged # delicious # guess # awkward # poured # went # angry # beautiful # impeccable # AVOID # quit # funny # m # chow # rge # left # bodes # handling # nigiri # waitress # passed # blown # relocated # greeted # desired # thinking # lost # hoping # witnessed # despicable # lighter # uploaded # seen # gotten # Wonderful # screwed # proven # final # tough # wasn't # hungry # appalling # simple # crispy # incredible # HAVE # expected # experiencing # choux # remember # indoor # arrives # ate # enjoyed # LOVED # different # decorated # promise # convenient # seasoned # horrible # large # efficient # provided # military # cold # cut # ethic # avocado # falling # wanted # SCREAMS # consistent # petrified # dine # mixed # exquisite # Do # smells # hit # ensued # brownish # Phenomenal # Avoid # flirting # lacking # boot # requested # performed # come # tried # wash # unwrapped # getting # daily # expanded # opened # stay # pleasant # satisfying # tasteless # thin # dripping # recommend # fresh # - # Hard # changing # outside # dressed # stop # opposed # try # grossed # extra # care # Hot # legit # flavored # Penne # handed # wait # focused # disagree # received # understand # better # insulted # feels # doubt # order # nasty # hot # given # end # perpared # great # generic # high # thought # exceptional # interesting # dead # bigger # Overpriced # means # wish # deserves # Perfect # Terrible # Large # listed # taste # damn # salty # watered # lacked # friendly # lived # realized # needed # charming # spotty # boring # SHOULD # missing # visited # love # tasty # original # avoided # Chinese # High # Total # sucked # honor # helped # Great # receives # held # tasted # rich # hate # pop # waste # long # gluten # look # grain # hits # added # profound # pale # cheated # hankering # kept # nude # cute # modern # breaks # beateous # inviting # strawberry # Thai # single # unique # disgusting # want # proclaimed # Cooked # caring # prepare # worth # cheap # dreamed # speedy # tops # supposed # stayed # greatest # editing # think # Will # hardest # delightful # looked # play # living # unsatisfying # veggie # fails # beat # Japanese # experienced # familiar # saying # sexy # Ordered # thumbs # cover # fellow # Loved # devine # Mediocre # stale # dirty- # shocked # customize # giant # apologize # Talk # refrained # pulled # pink # professional # return # typical # read # liked # usual # Generous # loyal # occasional # enthusiastic # cool # pneumatic # vegetarian # common # rinse # Paying # naan # charged # smeared # flavourful # appealing # outstanding # ridiculous # meet # worse # dirt # paid # leaves # happier # powdered # warm # cook # iced # surprised # untoasted # good # s # managed # smaller # touched # tiny # dried # ignore # hated # asking # Same # assure # nice # caught # overwhelmed # send # edible # close # hope # bloodiest # lovely # came # refreshing # unhealthy # mess # actual # late # felt # driving # watched # low # Outstanding # yellow # Good # preparing # bother # neat # fill # Go # Left # Indian # reheated # Weird # underwhelming # sore # fell # gooodd # highlighted # greedy # needs # recall # boba # mouthful # letting # describing # prepared # begin # trippy # raving # classic # Vegetarian # Went # drinking # drink # need # venturing # lettuce # disgraceful # Give # sporting # cramming # Must # Worse # green # pecan # replenished # smooth # recent # forgetting # Would # creamy # humiliated # charge # located # writing # inexpensive # toro # amazing # started # took # Fantastic # wants # Disappointed # packed # showed # hottest # grab # terrific # sals # heard # disgusted # reminds # priced # served # authentic # free # Third # staying # WILL # melt # fucking # dropped # tracked # cashew # contained # offered # fun # sat # mediocre # buying # returned # sugary # "
     ]
    }
   ],
   "source": [
    "print (len (r.features))\n",
    "for f in r.features:\n",
    "    print (f, end=' # ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (processed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NaiveBayes_Model' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7c21bb999fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprocessed_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-6645c7a64d8d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, debug)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# features = self.vectorizer.get_feature_names()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# self.vectorizer = CountVectorizer (ngram_range=(1, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NaiveBayes_Model' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "model.train (processed_X, y, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '15',\n",
       " '17',\n",
       " '1979',\n",
       " '20',\n",
       " '2007',\n",
       " '23',\n",
       " '30',\n",
       " '30s',\n",
       " '35',\n",
       " '40',\n",
       " '40min',\n",
       " '45',\n",
       " '4ths',\n",
       " '70',\n",
       " '85',\n",
       " '90',\n",
       " '99',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'accident',\n",
       " 'accommodation',\n",
       " 'accomodate',\n",
       " 'accordingly',\n",
       " 'accountant',\n",
       " 'ache',\n",
       " 'acknowledge',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'affordable',\n",
       " 'afternoon',\n",
       " 'ago',\n",
       " 'ahead',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'ala',\n",
       " 'albondigas',\n",
       " 'all',\n",
       " 'allergy',\n",
       " 'almond',\n",
       " 'amazing',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ample',\n",
       " 'andddd',\n",
       " 'angry',\n",
       " 'annoying',\n",
       " 'anticipate',\n",
       " 'anymore',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appetite',\n",
       " 'appetizer',\n",
       " 'apple',\n",
       " 'approval',\n",
       " 'area',\n",
       " 'arepa',\n",
       " 'aria',\n",
       " 'array',\n",
       " 'arrive',\n",
       " 'article',\n",
       " 'ask',\n",
       " 'assure',\n",
       " 'atmosphere',\n",
       " 'atrocious',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'auju',\n",
       " 'authentic',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'ayce',\n",
       " 'az',\n",
       " 'baba',\n",
       " 'baby',\n",
       " 'bachi',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bagel',\n",
       " 'bakery',\n",
       " 'baklava',\n",
       " 'ball',\n",
       " 'bamboo',\n",
       " 'banana',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bartender',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basically',\n",
       " 'batch',\n",
       " 'bathroom',\n",
       " 'batter',\n",
       " 'bay',\n",
       " 'bbq',\n",
       " 'be',\n",
       " 'bean',\n",
       " 'beat',\n",
       " 'beateous',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'begin',\n",
       " 'believe',\n",
       " 'bellagio',\n",
       " 'belly',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'binge',\n",
       " 'bird',\n",
       " 'biscuit',\n",
       " 'bisque',\n",
       " 'bit',\n",
       " 'bitches',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blanket',\n",
       " 'block',\n",
       " 'bloddy',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'boba',\n",
       " 'bode',\n",
       " 'boil',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'boot',\n",
       " 'boring',\n",
       " 'bother',\n",
       " 'bouchon',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breeze',\n",
       " 'brick',\n",
       " 'bring',\n",
       " 'brisket',\n",
       " 'brother',\n",
       " 'brownish',\n",
       " 'brunch',\n",
       " 'bruschetta',\n",
       " 'brushfire',\n",
       " 'buck',\n",
       " 'buffet',\n",
       " 'bug',\n",
       " 'building',\n",
       " 'buldogis',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'burn',\n",
       " 'burrittos',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'bussell',\n",
       " 'busy',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'bye',\n",
       " 'caballero',\n",
       " 'caesar',\n",
       " 'cafe',\n",
       " 'café',\n",
       " 'cake',\n",
       " 'calamari',\n",
       " 'calligraphy',\n",
       " 'calling',\n",
       " 'camelback',\n",
       " 'can',\n",
       " 'cannoli',\n",
       " 'cape',\n",
       " 'caper',\n",
       " 'car',\n",
       " 'carb',\n",
       " 'care',\n",
       " 'carly',\n",
       " 'carpaccio',\n",
       " 'cart',\n",
       " 'cartel',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashew',\n",
       " 'cashier',\n",
       " 'casino',\n",
       " 'catch',\n",
       " 'caterpillar',\n",
       " 'cause',\n",
       " 'cavier',\n",
       " 'certainly',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'change',\n",
       " 'char',\n",
       " 'charcoal',\n",
       " 'charge',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'cheated',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheese',\n",
       " 'cheeseburger',\n",
       " 'cheesecurd',\n",
       " 'chef',\n",
       " 'chewy',\n",
       " 'chicken',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipolte',\n",
       " 'chipotle',\n",
       " 'chocolate',\n",
       " 'choose',\n",
       " 'choux',\n",
       " 'chow',\n",
       " 'christmas',\n",
       " 'cibo',\n",
       " 'circumstance',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'clean',\n",
       " 'climb',\n",
       " 'close',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cocktail',\n",
       " 'coconut',\n",
       " 'cod',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'color',\n",
       " 'combination',\n",
       " 'combo',\n",
       " 'combos',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'common',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'compliment',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'conclusion',\n",
       " 'condiment',\n",
       " 'connisseur',\n",
       " 'connoisseur',\n",
       " 'consider',\n",
       " 'consistent',\n",
       " 'construct',\n",
       " 'contain',\n",
       " 'container',\n",
       " 'continue',\n",
       " 'convenient',\n",
       " 'cook',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'corn',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'correction',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'cotta',\n",
       " 'count',\n",
       " 'couple',\n",
       " 'coupon',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'coziness',\n",
       " 'crab',\n",
       " 'cram',\n",
       " 'cranberry',\n",
       " 'craving',\n",
       " 'crawfish',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'crema',\n",
       " 'crepe',\n",
       " 'crisp',\n",
       " 'crispy',\n",
       " 'crostini',\n",
       " 'crouton',\n",
       " 'crowd',\n",
       " 'crumby',\n",
       " 'crust',\n",
       " 'crusty',\n",
       " 'crystals',\n",
       " 'crêpe',\n",
       " 'cuisine',\n",
       " 'curry',\n",
       " 'customer',\n",
       " 'customize',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'daily',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decision',\n",
       " 'decor',\n",
       " 'decorate',\n",
       " 'decorated',\n",
       " 'dedicated',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'def',\n",
       " 'definately',\n",
       " 'definitely',\n",
       " 'degree',\n",
       " 'del',\n",
       " 'delicate',\n",
       " 'delicioso',\n",
       " 'delicious',\n",
       " 'deliciously',\n",
       " 'delight',\n",
       " 'delightful',\n",
       " 'delish',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'denny',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'deserve',\n",
       " 'desire',\n",
       " 'despicable',\n",
       " 'despite',\n",
       " 'dessert',\n",
       " 'deuchebaggery',\n",
       " 'devine',\n",
       " 'die',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dime',\n",
       " 'dine',\n",
       " 'dining',\n",
       " 'dinner',\n",
       " 'dip',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'disagree',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'disapppointment',\n",
       " 'disaster',\n",
       " 'disbelief',\n",
       " 'discount',\n",
       " 'disgrace',\n",
       " 'disgraceful',\n",
       " 'disgust',\n",
       " 'disgusting',\n",
       " 'dish',\n",
       " 'dispenser',\n",
       " 'disrespect',\n",
       " 'diverse',\n",
       " 'do',\n",
       " 'dog',\n",
       " 'dollar',\n",
       " 'donut',\n",
       " 'door',\n",
       " 'dos',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'douchey',\n",
       " 'dough',\n",
       " 'doughy',\n",
       " 'downright',\n",
       " 'downside',\n",
       " 'downtown',\n",
       " 'drag',\n",
       " 'drastically',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'drench',\n",
       " 'dress',\n",
       " 'dressing',\n",
       " 'drink',\n",
       " 'drip',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'dude',\n",
       " 'duo',\n",
       " 'dust',\n",
       " 'dylan',\n",
       " 'easily',\n",
       " 'eat',\n",
       " 'eclectic',\n",
       " 'edible',\n",
       " 'edinburgh',\n",
       " 'edit',\n",
       " 'eel',\n",
       " 'eew',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'elegantly',\n",
       " 'elk',\n",
       " 'email',\n",
       " 'employee',\n",
       " 'end',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'ensue',\n",
       " 'enthusiastic',\n",
       " 'entire',\n",
       " 'entree',\n",
       " 'equally',\n",
       " 'especially',\n",
       " 'establishment',\n",
       " 'etc',\n",
       " 'ethic',\n",
       " 'eve',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'exactly',\n",
       " 'excalibur',\n",
       " 'exceed',\n",
       " 'excellent',\n",
       " 'exceptional',\n",
       " 'excuse',\n",
       " 'expand',\n",
       " 'expect',\n",
       " 'expectation',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'expert',\n",
       " 'exquisite',\n",
       " 'extensive',\n",
       " 'extra',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyed',\n",
       " 'fabulous',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'falafel',\n",
       " 'fall',\n",
       " 'familiar',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fancy',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fare',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'fav',\n",
       " 'favor',\n",
       " 'favorite',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'fella',\n",
       " 'fellow',\n",
       " 'fiancé',\n",
       " 'figure',\n",
       " 'filet',\n",
       " 'fill',\n",
       " 'fillet',\n",
       " 'filling',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'finish',\n",
       " 'fireball',\n",
       " 'firehouse',\n",
       " 'fish',\n",
       " 'flair',\n",
       " 'flat',\n",
       " 'flavor',\n",
       " 'flavorful',\n",
       " 'flavorless',\n",
       " 'flavourful',\n",
       " 'flirt',\n",
       " 'flop',\n",
       " 'flower',\n",
       " 'fluffy',\n",
       " 'fly',\n",
       " 'fo',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'folk',\n",
       " 'fondue',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forth',\n",
       " 'forward',\n",
       " 'francisco',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'freezing',\n",
       " 'frenchman',\n",
       " 'fresh',\n",
       " 'fridays',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'frozen',\n",
       " 'fruit',\n",
       " 'frustrated',\n",
       " 'fry',\n",
       " 'fs',\n",
       " 'fuck',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'furthermore',\n",
       " 'fuzzy',\n",
       " 'ganoush',\n",
       " 'garden',\n",
       " 'garlic',\n",
       " 'gas',\n",
       " 'gc',\n",
       " 'gem',\n",
       " 'generic',\n",
       " 'generous',\n",
       " 'genuinely',\n",
       " 'get',\n",
       " 'giant',\n",
       " 'girlfriend',\n",
       " 'give',\n",
       " 'glad',\n",
       " 'glance',\n",
       " 'glass',\n",
       " 'glove',\n",
       " 'gluten',\n",
       " 'go',\n",
       " 'goat',\n",
       " 'godfather',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'google',\n",
       " 'gooodd',\n",
       " 'gordon',\n",
       " 'gourmet',\n",
       " 'grab',\n",
       " 'grain',\n",
       " 'grandmother',\n",
       " 'gratitude',\n",
       " 'gratuity',\n",
       " 'grease',\n",
       " 'greasy',\n",
       " 'great',\n",
       " 'greedy',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greet',\n",
       " 'grill',\n",
       " 'gringos',\n",
       " 'gristle',\n",
       " 'grocery',\n",
       " 'gross',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'guacamole',\n",
       " 'guess',\n",
       " 'guest',\n",
       " 'guy',\n",
       " 'gyro',\n",
       " 'gyros',\n",
       " 'ha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'halibut',\n",
       " 'hamburger',\n",
       " 'han',\n",
       " 'hand',\n",
       " 'handed',\n",
       " 'handle',\n",
       " 'handmade',\n",
       " 'hands',\n",
       " 'hanker',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'hate',\n",
       " 'haunt',\n",
       " 'have',\n",
       " 'hawaiian',\n",
       " 'head',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heimer',\n",
       " 'hell',\n",
       " 'hella',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hereas',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'highlight',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'hip',\n",
       " 'hiro',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'homemade',\n",
       " 'honeslty',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'honor',\n",
       " 'hook',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'horrible',\n",
       " 'hospitality',\n",
       " 'host',\n",
       " 'hostess',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'huevos',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'humiliate',\n",
       " 'hummus',\n",
       " 'hunan',\n",
       " 'hungry',\n",
       " 'hurry',\n",
       " 'husband',\n",
       " 'hut',\n",
       " 'ians',\n",
       " 'ice',\n",
       " 'iced',\n",
       " 'idea',\n",
       " 'ignore',\n",
       " 'imagination',\n",
       " 'imaginative',\n",
       " 'imagine',\n",
       " 'immediately',\n",
       " 'impeccable',\n",
       " 'impress',\n",
       " 'impressed',\n",
       " 'impressive',\n",
       " 'inch',\n",
       " 'include',\n",
       " 'inconsiderate',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indian',\n",
       " 'indicate',\n",
       " 'indoor',\n",
       " 'industry',\n",
       " 'inexpensive',\n",
       " 'inflate',\n",
       " 'informative',\n",
       " 'ingredient',\n",
       " 'insanely',\n",
       " 'inside',\n",
       " 'inspire',\n",
       " 'instantly',\n",
       " 'instead',\n",
       " 'insult',\n",
       " 'interesting',\n",
       " 'interior',\n",
       " 'inviting',\n",
       " 'ironman',\n",
       " 'italian',\n",
       " 'item',\n",
       " 'jalapeno',\n",
       " 'jamaican',\n",
       " 'japanese',\n",
       " 'jeff',\n",
       " 'jenni',\n",
       " 'jerk',\n",
       " 'jewel',\n",
       " 'job',\n",
       " 'joey',\n",
       " 'join',\n",
       " 'joint',\n",
       " 'joke',\n",
       " 'joy',\n",
       " 'judge',\n",
       " 'juice',\n",
       " 'jury',\n",
       " 'kabuki',\n",
       " 'keep',\n",
       " 'key',\n",
       " 'khao',\n",
       " 'kid',\n",
       " 'kiddo',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'kitchen',\n",
       " 'know',\n",
       " 'known',\n",
       " 'lack',\n",
       " 'lacking',\n",
       " 'ladies',\n",
       " 'lady',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'las',\n",
       " 'lastly',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latte',\n",
       " 'law',\n",
       " 'lawyer',\n",
       " 'lb',\n",
       " 'leather',\n",
       " 'leave',\n",
       " 'leftover',\n",
       " 'leg',\n",
       " 'legit',\n",
       " 'lemon',\n",
       " 'let',\n",
       " 'letdown',\n",
       " 'lettuce',\n",
       " 'level',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lighting',\n",
       " 'lightly',\n",
       " 'like',\n",
       " 'liking',\n",
       " 'lil',\n",
       " 'limit',\n",
       " 'lined',\n",
       " 'list',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lobster',\n",
       " 'locate',\n",
       " 'location',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'lordy',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'loudly',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'lover',\n",
       " 'low',\n",
       " 'lox',\n",
       " 'loyal',\n",
       " 'luck',\n",
       " 'luke',\n",
       " 'lukewarm',\n",
       " 'lunch',\n",
       " 'mac',\n",
       " 'macarons',\n",
       " 'madhouse',\n",
       " 'madison',\n",
       " 'magazine',\n",
       " 'magic',\n",
       " 'main',\n",
       " 'maine',\n",
       " 'maintain',\n",
       " 'make',\n",
       " 'mall',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'management',\n",
       " 'manager',\n",
       " 'mandalay',\n",
       " 'mango',\n",
       " 'margarita',\n",
       " 'margaritas',\n",
       " 'maria',\n",
       " 'market',\n",
       " 'marrow',\n",
       " 'martini',\n",
       " 'mary',\n",
       " 'massive',\n",
       " 'maybe',\n",
       " 'mayo',\n",
       " 'meal',\n",
       " 'mean',\n",
       " 'meat',\n",
       " 'meatball',\n",
       " 'meatloaf',\n",
       " 'mediocre',\n",
       " 'mediterranean',\n",
       " 'medium',\n",
       " 'meet',\n",
       " 'meh',\n",
       " 'mein',\n",
       " 'mellow',\n",
       " 'melt',\n",
       " 'melted',\n",
       " 'memory',\n",
       " 'mention',\n",
       " 'menu',\n",
       " 'menus',\n",
       " 'mesquite',\n",
       " 'mess',\n",
       " 'metro',\n",
       " 'mexican',\n",
       " 'mgm',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'mile',\n",
       " 'military',\n",
       " 'milk',\n",
       " 'milkshake',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'minutes',\n",
       " 'mirage',\n",
       " 'miss',\n",
       " 'mistake',\n",
       " 'mixed',\n",
       " 'mmmm',\n",
       " 'modern',\n",
       " 'moist',\n",
       " 'mojito',\n",
       " 'mom',\n",
       " 'money',\n",
       " 'monster',\n",
       " 'months',\n",
       " 'mood',\n",
       " 'mortify',\n",
       " 'mouth',\n",
       " 'mouthful',\n",
       " 'movie',\n",
       " 'moz',\n",
       " 'mozzarella',\n",
       " 'muffin',\n",
       " 'multi',\n",
       " 'multiple',\n",
       " 'mushroom',\n",
       " 'music',\n",
       " 'mussel',\n",
       " 'my',\n",
       " 'naan',\n",
       " 'nachos',\n",
       " 'nan',\n",
       " 'nargile',\n",
       " 'nasty',\n",
       " 'nay',\n",
       " 'nearly',\n",
       " 'neat',\n",
       " 'need',\n",
       " 'needless',\n",
       " 'negligent',\n",
       " 'neighborhood',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nigiri',\n",
       " 'ninja',\n",
       " 'nobu',\n",
       " 'noca',\n",
       " 'non',\n",
       " 'noodle',\n",
       " 'north',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nude',\n",
       " 'number',\n",
       " 'nut',\n",
       " 'nutshell',\n",
       " 'nyc',\n",
       " 'obviously',\n",
       " 'occasion',\n",
       " 'occasional',\n",
       " 'offer',\n",
       " 'officially',\n",
       " 'oh',\n",
       " 'ohhh',\n",
       " 'oil',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'olive',\n",
       " 'omelet',\n",
       " 'omg',\n",
       " 'one',\n",
       " 'onion',\n",
       " 'open',\n",
       " 'operation',\n",
       " 'opinion',\n",
       " 'opportunity',\n",
       " 'oppose',\n",
       " 'option',\n",
       " 'order',\n",
       " 'ordering',\n",
       " 'original',\n",
       " 'otto',\n",
       " 'outdoor',\n",
       " 'outrageously',\n",
       " 'outshine',\n",
       " 'outside',\n",
       " 'outstanding',\n",
       " 'outta',\n",
       " 'oven',\n",
       " 'overall',\n",
       " 'overcook',\n",
       " 'overhaul',\n",
       " 'overprice',\n",
       " 'overpriced',\n",
       " 'overwhelmed',\n",
       " 'own',\n",
       " 'owner',\n",
       " 'owners',\n",
       " 'oyster',\n",
       " 'pace',\n",
       " 'pack',\n",
       " 'palate',\n",
       " 'pale',\n",
       " 'palm',\n",
       " 'pan',\n",
       " 'pancake',\n",
       " 'panna',\n",
       " 'paper',\n",
       " 'par',\n",
       " 'paradise',\n",
       " 'parent',\n",
       " 'particular',\n",
       " 'party',\n",
       " 'pass',\n",
       " 'past',\n",
       " 'pasta',\n",
       " 'pastry',\n",
       " 'pat',\n",
       " 'patio',\n",
       " 'patron',\n",
       " 'patty',\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(model.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'like' in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict (\"I didn't like the buffet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict (\"I kind of not liked the service.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict (\"Food was good but service could have been better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict (\"Buffet was ok but service ruined it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict (\" I didn't like the food.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{100, 92, 86, 84}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"food was not tasty\"\n",
    "print (model.pos(sen))\n",
    "model.predict (sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
