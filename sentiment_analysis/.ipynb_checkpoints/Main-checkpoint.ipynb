{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-1b7d9c92b374>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-1b7d9c92b374>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    self.splits[i] = [x for x in self.splits[i] if x.i not in stpwrds]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__ (self, reviews):\n",
    "        self.nlp = spacy.load ('en_core_web_sm')\n",
    "        self.neg_words = pickle.load (open (\"neg_words.pkl\", \"rb\"))\n",
    "        self.neg_words.add ('not')\n",
    "        \n",
    "        self.reviews = [self.nlp(x.lower()) for x in reviews]\n",
    "        \n",
    "        self.stop_words = STOP_WORDS\n",
    "        self.stop_words.update (string.punctuation)\n",
    "        self.stop_words = set([x for x in self.stop_words if x not in self.neg_words])\n",
    "        \n",
    "        self.docs = []\n",
    "    \n",
    "    def drop_adverbs (self):\n",
    "        for index in range(len(self.splits)):\n",
    "            self.split_pattern = \"([a-z]+)\\s*[.,]+(\\s*)\"\n",
    "\n",
    "            advbs = set()\n",
    "            for t in self.splits[index]:\n",
    "                if t.pos == 86 and t.text not in self.neg_words:\n",
    "                    advbs.add (t.i)\n",
    "            self.splits[index] = [x for x in self.splits[index] if x.i not in advbs]\n",
    "            \n",
    "    def drop_stopwords(self):\n",
    "        # Remove all stop words that are present in the neg_words, TILL NOW: only 'not'\n",
    "        for i in range (len (self.splits)):\n",
    "            stpwrds = set ()\n",
    "            for t in self.splits[i]:\n",
    "                if t.text.lower() in self.stop_words:\n",
    "                    stpwrds.add (t.i)\n",
    "        self.split_pattern = re.compile (r\"(\\s|-)\")\n",
    "            self.splits[i] = [x for x in self.splits[i] if x.i not in stpwrds]\n",
    "\n",
    "    def sentence_splitter (self):\n",
    "        self.splits = []\n",
    "        def splitter (sentence):\n",
    "            start = 0\n",
    "            counter = 0\n",
    "            for token in sentence:\n",
    "                if token.pos == 89 or token.text.strip() == ',':\n",
    "                    if counter > start:\n",
    "                        self.splits.append (sentence[start: counter])\n",
    "                    start = counter + 1\n",
    "                counter += 1\n",
    "            #print (sentence[start: ])\n",
    "            if len (sentence[start: counter]) > 0:\n",
    "                self.splits.append (sentence[start: counter])\n",
    "        \n",
    "        for doc in self.reviews:\n",
    "            for sent in doc.sents:\n",
    "                #print (\"Sentence: \", sent)\n",
    "                splitter (sent)\n",
    "        #return splits\n",
    "        \n",
    "    def feature_extraction (self):\n",
    "        # To be done when splits have SPAN Objects\n",
    "        # i.e. before any drop_*** methods()\n",
    "        self.features = []\n",
    "        for entry in self.splits:\n",
    "            # For every entry, we need to pick out a noun and an adjective\n",
    "            nouns=[]\n",
    "            adjs=[]\n",
    "            vbs = []\n",
    "            for t in entry:\n",
    "                if t.pos == 92 or t.pos == 96:\n",
    "                    nouns.append (t)\n",
    "                elif t.pos == 84:\n",
    "                    adjs.append (t)\n",
    "                elif t.pos == 100:\n",
    "                    vbs.append (t)\n",
    "            if len (adjs) == 0:\n",
    "                adjs = vbs\n",
    "            self.features.append ( \n",
    "                                        ( ', '.join(map(str, nouns)), ', '.join(map(str, adjs)) ),\n",
    "                                  )\n",
    "        \n",
    "    def prepare(self):\n",
    "        self.sentence_splitter()\n",
    "        self.feature_extraction()\n",
    "        self.drop_adverbs()\n",
    "        \n",
    "    def pprint (self):\n",
    "        counter = 0\n",
    "        for split in sa.splits:\n",
    "            sent = ' '.join (map(str, split))\n",
    "            print (sent)\n",
    "            scores = sia.polarity_scores (sent)\n",
    "            print (scores)\n",
    "            print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "            if scores['compound'] > 0:\n",
    "                print (\"POSITIVE\")\n",
    "            elif scores['compound'] == 0:\n",
    "                print (\"NEUTRAL\")\n",
    "            else:\n",
    "                print (\"NEGATIVE\");\n",
    "            print()\n",
    "            counter += 1\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Both Veg and Non-Veg Items were great\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sentence_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[both veg, non-veg items were great]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type (sa.splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa.drop_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.drop_adverbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/balor/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    print (f\"{'POSITIVE' if scores['compound'] > 0 else 'NEGATIVE'}\")\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reviews = [\n",
    "    \"Movie was great but Cinema Hall was not cool.\",\n",
    "    \"Buffet was great, but ambience not so good.\",\n",
    "]\"\"\"\n",
    "\n",
    "reviews = [\n",
    "    \" First time I tried this outlet in c.p but got disappointed with their service. Marination and the taste of starters was really not good. This outlet maybe as per review stars are good just as they serve alcohol. But I will not opt this outlet as taste matters alcohol is secondary thing. Chef must see the taste and serve the food as per barbeque nation standards.I am giving 3 stars just for the hospitality of the staff which was really very good.\"\n",
    "]\n",
    "\n",
    "reviews = [\n",
    "    \" Yes they server really good food here. Barbeque nation faces stiff competition around but keeps up well with the competitors. Food variety was good, starters were good!\n",
    "    Drinks were okay.\n",
    "Its Barbeque Nation, it goes obvious that Staff was exceptional. We love the Service here.\n",
    "\n",
    "Only issue is the Ambience here. I feel they need to up the Ambience. Can be better sitting arrangement or better local arch. We sat at corner seat which was not very comfortable and was not well placed. Rest enjoyed the food here. Recommended.\n",
    "\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"\"\"\n",
    "     Yes they server really good food here. Barbeque nation faces stiff competition around but keeps up well with the competitors. Food variety was good, starters were good!\n",
    "Drinks were okay.\n",
    "Its Barbeque Nation, it goes obvious that Staff was exceptional. We love the Service here.\n",
    "\n",
    "Only issue is the Ambience here. I feel they need to up the Ambience. Can be better sitting arrangement or better local arch. We sat at corner seat which was not very comfortable and was not well placed. Rest enjoyed the food here. Recommended.\n",
    "\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \" both veg and non veg foods were fine.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer(reviews)\n",
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = sa.nlp(reviews[0])\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores (\"There is so much of variety in stuffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = sa.nlp (\"Varities of Veg and non Veg foods was there.\")\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'Varities of Veg and non-veg foods was there.'\n",
    "print (sia.polarity_scores (r))\n",
    "\n",
    "doc = sa.nlp (r)\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \" First time I tried this outlet in c.p but got disappointed with their service. Marination and the taste of starters was really not good. This outlet maybe as per review stars are good just as they serve alcohol. But I will not opt this outlet as taste matters alcohol is secondary thing. Chef must see the taste and serve the food as per barbeque nation standards.I am giving 3 stars just for the hospitality of the staff which was really very good.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)\n",
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first time i tried this outlet in c.p\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: time, outlet \tFEATURES: first     \tNEUTRAL\n",
      "\n",
      "got disappointed with their service .\n",
      "{'neg': 0.437, 'neu': 0.563, 'pos': 0.0, 'compound': -0.4767}\n",
      "ENTITY: service    \tFEATURES: disappointed\tNEGATIVE\n",
      "\n",
      "marination\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: marination \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "the taste of starters was not good .\n",
      "{'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.3412}\n",
      "ENTITY: taste, starters \tFEATURES: good      \tNEGATIVE\n",
      "\n",
      "this outlet as per review stars are good as they serve alcohol .\n",
      "{'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'compound': 0.4404}\n",
      "ENTITY: outlet, review, stars, alcohol \tFEATURES: good      \tPOSITIVE\n",
      "\n",
      "i will not opt this outlet as taste matters alcohol is secondary thing .\n",
      "{'neg': 0.0, 'neu': 0.909, 'pos': 0.091, 'compound': 0.0258}\n",
      "ENTITY: outlet, taste, matters, alcohol, thing \tFEATURES: secondary \tPOSITIVE\n",
      "\n",
      "chef must see the taste\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: chef, taste \tFEATURES: must, see \tNEUTRAL\n",
      "\n",
      "serve the food as per barbeque nation standards.i am giving 3 stars for the hospitality of the staff which was good .\n",
      "{'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'compound': 0.6486}\n",
      "ENTITY: food, nation, stars, hospitality, staff \tFEATURES: barbeque, good\tPOSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.16, 'neu': 0.794, 'pos': 0.046, 'compound': -0.9096}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"If you are about to throw birthday parties with family and close frenzz then barbeque nation has it all. From gogappe to veg n non-veg starters to veg n non- veg main course to deserts, kulfies, gulab jamun , rasmalai everything. What else you could demand for than having served all on ur plate. All you need to do is sit back with empty tummy and enjoy each n every ounce of its food...\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)\n",
    "sa.prepare ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you are about to throw birthday parties with family\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.4019}\n",
      "ENTITY: birthday, parties, family \tFEATURES: about     \tPOSITIVE\n",
      "\n",
      "close frenzz barbeque nation has it all .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: frenzz, nation \tFEATURES: barbeque  \tNEUTRAL\n",
      "\n",
      "from gogappe to veg\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: gogappe    \tFEATURES: veg       \tNEUTRAL\n",
      "\n",
      "non - veg starters to veg\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: starters   \tFEATURES: non, -, veg\tNEUTRAL\n",
      "\n",
      "non- veg main course to deserts\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: non-, course, deserts \tFEATURES: veg, main \tNEUTRAL\n",
      "\n",
      "kulfies\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: kulfies    \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "gulab jamun\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: gulab, jamun \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "rasmalai everything .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: everything \tFEATURES: rasmalai  \tNEUTRAL\n",
      "\n",
      "what you could demand for than having served ur plate .\n",
      "{'neg': 0.143, 'neu': 0.857, 'pos': 0.0, 'compound': -0.128}\n",
      "ENTITY: plate      \tFEATURES: could, demand, having, served\tNEGATIVE\n",
      "\n",
      "all you need to do is sit with empty tummy\n",
      "{'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'compound': -0.2023}\n",
      "ENTITY: tummy      \tFEATURES: empty     \tNEGATIVE\n",
      "\n",
      "enjoy each n every ounce of its food ...\n",
      "{'neg': 0.0, 'neu': 0.686, 'pos': 0.314, 'compound': 0.4939}\n",
      "ENTITY: n, ounce, food \tFEATURES: enjoy     \tPOSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.044, 'neu': 0.878, 'pos': 0.078, 'compound': 0.5574}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"Easily one of the worst places that I have been to in recent times.We ordered classic martini along with dahi kebabs. Their martinis were so bad we had to cancel them. Dahi kebabs had just a pea size layer of dahi in a sort of bread and alu tikki. I am sorry but that is not how you make dahi kebabs. The look and feel of the place is also quite a turn off.Would definitely advise to give this place a miss.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the worst places that i have been to in recent times.we ordered classic martini along with dahi kebabs .\n",
      "{'neg': 0.186, 'neu': 0.814, 'pos': 0.0, 'compound': -0.6249}\n",
      "ENTITY: places, martini, dahi, kebabs \tFEATURES: worst, recent, classic\tNEGATIVE\n",
      "\n",
      "their martinis were bad we had to cancel them .\n",
      "{'neg': 0.44, 'neu': 0.56, 'pos': 0.0, 'compound': -0.6705}\n",
      "ENTITY: martinis   \tFEATURES: bad       \tNEGATIVE\n",
      "\n",
      "dahi kebabs had a pea size layer of dahi in a sort of bread\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: dahi, kebabs, pea, size, layer, dahi, sort, bread \tFEATURES: had       \tNEUTRAL\n",
      "\n",
      "alu tikki .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: alu, tikki \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "i am sorry\n",
      "{'neg': 0.565, 'neu': 0.435, 'pos': 0.0, 'compound': -0.0772}\n",
      "ENTITY:            \tFEATURES: sorry     \tNEGATIVE\n",
      "\n",
      "that is not you make dahi kebabs .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: dahi, kebabs \tFEATURES: is, make  \tNEUTRAL\n",
      "\n",
      "the look\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: look       \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "feel of the place is quite a turn off.would advise to give this place a miss .\n",
      "{'neg': 0.11, 'neu': 0.89, 'pos': 0.0, 'compound': -0.1531}\n",
      "ENTITY: place, turn, place, miss \tFEATURES: feel, is, off.would, advise, give\tNEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (\"that is not how you make dahi kababs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (\"You do not how to cook food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sia.polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'compound': -0.4939}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x('The servers overthere are fools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.524, 'neu': 0.476, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"The waiters were idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.352, 'neu': 0.519, 'pos': 0.13, 'compound': -0.6124}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"I like the benetton tshirts but their pants are bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.196, 'neu': 0.522, 'pos': 0.283, 'compound': 0.25}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"Benetton tshirts are bad but i like their pants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [ \"I like the benetton tshirts but their pants were not okay\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like the benetton tshirts\n",
      "{'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.3612}\n",
      "ENTITY: benetton, tshirts \tFEATURES: like      \tPOSITIVE\n",
      "\n",
      "their pants were not okay\n",
      "{'neg': 0.294, 'neu': 0.706, 'pos': 0.0, 'compound': -0.1695}\n",
      "ENTITY: pants      \tFEATURES: okay      \tNEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer(r)\n",
    "sa.prepare()\n",
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 95 PRON 13656873538139661788 PRP\n",
      "am 100 VERB 9188597074677201817 VBP\n",
      "balor.i 96 PROPN 15794550382381185553 NNP\n",
      "am 100 VERB 9188597074677201817 VBP\n",
      "Anshuman 84 ADJ 10554686591937588953 JJ\n"
     ]
    }
   ],
   "source": [
    "doc = sa.nlp (\"i am balor.i am Anshuman\")\n",
    "for t in doc:\n",
    "    print (t, t.pos, t.pos_, t.tag, t.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[i am balor.i am Anshuman]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[i, am, am, anshuman]]\n",
      "i am am anshuman\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY:            \tFEATURES: anshuman  \tNEUTRAL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer(['i am balor.i am Anshuman'])\n",
    "sa.prepare()\n",
    "print (sa.splits)\n",
    "sa.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentimentAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-97d23518153d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"I am going home.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentimentAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer()\n",
    "doc = sa.nlp (\"I am going home.\")\n",
    "for token in doc:\n",
    "    print (token, token.pos, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
