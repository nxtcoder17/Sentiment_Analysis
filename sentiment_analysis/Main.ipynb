{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__ (self, reviews):\n",
    "        self.nlp = spacy.load ('en_core_web_sm')\n",
    "        self.neg_words = pickle.load (open (\"neg_words.pkl\", \"rb\"))\n",
    "        self.neg_words.add ('not')\n",
    "        \n",
    "        self.reviews = [self.nlp(x.lower()) for x in reviews]\n",
    "        \n",
    "        self.stop_words = STOP_WORDS\n",
    "        self.stop_words.update (string.punctuation)\n",
    "        self.stop_words = set([x for x in self.stop_words if x not in self.neg_words])\n",
    "        \n",
    "        self.docs = []\n",
    "    \n",
    "    def drop_adverbs (self):\n",
    "        for index in range(len(self.splits)):\n",
    "            self.split_pattern = \"([a-z]+)\\s*[.,]+(\\s*)\"\n",
    "            advbs = set()\n",
    "            for t in self.splits[index]:\n",
    "                if t.pos == 86 and t.text not in self.neg_words:\n",
    "                    advbs.add (t.i)\n",
    "            self.splits[index] = [x for x in self.splits[index] if x.i not in advbs]\n",
    "            \n",
    "    def drop_stopwords(self):\n",
    "        # Remove all stop words that are present in the neg_words, TILL NOW: only 'not'\n",
    "        for i in range (len (self.splits)):\n",
    "            stpwrds = set ()\n",
    "            for t in self.splits[i]:\n",
    "                if t.text.lower() in self.stop_words:\n",
    "                    stpwrds.add (t.i)\n",
    "        self.split_pattern = re.compile (r\"(\\s|-)\")\n",
    "        self.splits[i] = [x for x in self.splits[i] if x.i not in stpwrds]\n",
    "\n",
    "    def sentence_splitter (self):\n",
    "        self.splits = []\n",
    "        def splitter (sentence):\n",
    "            start = 0\n",
    "            counter = 0\n",
    "            for token in sentence:\n",
    "                if token.pos == 89 or token.text.strip() == ',':\n",
    "                    if counter > start:\n",
    "                        self.splits.append (sentence[start: counter])\n",
    "                    start = counter + 1\n",
    "                counter += 1\n",
    "            #print (sentence[start: ])\n",
    "            if len (sentence[start: counter]) > 0:\n",
    "                self.splits.append (sentence[start: counter])\n",
    "        \n",
    "        for doc in self.reviews:\n",
    "            for sent in doc.sents:\n",
    "                #print (\"Sentence: \", sent)\n",
    "                splitter (sent)\n",
    "        #return splits\n",
    "        \n",
    "    def feature_extraction (self):\n",
    "        # To be done when splits have SPAN Objects\n",
    "        # i.e. before any drop_*** methods()\n",
    "        self.features = []\n",
    "        for entry in self.splits:\n",
    "            # For every entry, we need to pick out a noun and an adjective\n",
    "            nouns=[]\n",
    "            adjs=[]\n",
    "            vbs = []\n",
    "            for t in entry:\n",
    "                if t.pos == 92 or t.pos == 96:\n",
    "                    nouns.append (t)\n",
    "                elif t.pos == 84:\n",
    "                    adjs.append (t)\n",
    "                elif t.pos == 100:\n",
    "                    vbs.append (t)\n",
    "            if len (adjs) == 0:\n",
    "                adjs = vbs\n",
    "            self.features.append ( \n",
    "                                        ( ', '.join(map(str, nouns)), ', '.join(map(str, adjs)) ),\n",
    "                                  )\n",
    "        \n",
    "    def prepare(self):\n",
    "        self.sentence_splitter()\n",
    "        self.feature_extraction()\n",
    "        self.drop_adverbs()\n",
    "        \n",
    "    def pprint (self):\n",
    "        counter = 0\n",
    "        for split in sa.splits:\n",
    "            sent = ' '.join (map(str, split))\n",
    "            print (sent)\n",
    "            scores = sia.polarity_scores (sent)\n",
    "            print (scores)\n",
    "            print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "            if scores['compound'] > 0:\n",
    "                print (\"POSITIVE\")\n",
    "            elif scores['compound'] == 0:\n",
    "                print (\"NEUTRAL\")\n",
    "            else:\n",
    "                print (\"NEGATIVE\");\n",
    "            print()\n",
    "            counter += 1\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Both Veg and Non-Veg Items were great\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.sentence_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[veg, non-veg items were great]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (sa.splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa.drop_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[veg, non-veg items were great]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.drop_adverbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[veg], [non, -, veg, items, were, great]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/balor/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Both Veg and Non-Veg Items were great']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veg\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: veg        \tFEATURES:           \tNEGATIVE\n",
      "\n",
      "non - veg items were great\n",
      "{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6249}\n",
      "ENTITY: items      \tFEATURES: non, -, veg, great\tPOSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    print (f\"{'POSITIVE' if scores['compound'] > 0 else 'NEGATIVE'}\")\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reviews = [\n",
    "    \"Movie was great but Cinema Hall was not cool.\",\n",
    "    \"Buffet was great, but ambience not so good.\",\n",
    "]\"\"\"\n",
    "\n",
    "reviews = [\n",
    "    \" First time I tried this outlet in c.p but got disappointed with their service. Marination and the taste of starters was really not good. This outlet maybe as per review stars are good just as they serve alcohol. But I will not opt this outlet as taste matters alcohol is secondary thing. Chef must see the taste and serve the food as per barbeque nation standards.I am giving 3 stars just for the hospitality of the staff which was really very good.\"\n",
    "]\n",
    "\n",
    "reviews = [\n",
    "    \"\"\"Yes they server really good food here. Barbeque nation faces stiff competition around but keeps up well with the competitors. Food variety was good, starters were good!\n",
    "    Drinks were okay.\n",
    "Its Barbeque Nation, it goes obvious that Staff was exceptional. We love the Service here.\n",
    "\n",
    "Only issue is the Ambience here. I feel they need to up the Ambience. Can be better sitting arrangement or better local arch. We sat at corner seat which was not very comfortable and was not well placed. Rest enjoyed the food here. Recommended.\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"\"\"\n",
    "     Yes they server really good food here. Barbeque nation faces stiff competition around but keeps up well with the competitors. Food variety was good, starters were good!\n",
    "Drinks were okay.\n",
    "Its Barbeque Nation, it goes obvious that Staff was exceptional. We love the Service here.\n",
    "\n",
    "Only issue is the Ambience here. I feel they need to up the Ambience. Can be better sitting arrangement or better local arch. We sat at corner seat which was not very comfortable and was not well placed. Rest enjoyed the food here. Recommended.\n",
    "\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = [\n",
    "#    \" both veg and non veg foods were fine.\"\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer(reviews)\n",
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      yes they server good food .\n",
      "{'neg': 0.0, 'neu': 0.349, 'pos': 0.651, 'compound': 0.6808}\n",
      "ENTITY: food       \tFEATURES: good      \tPOSITIVE\n",
      "\n",
      "barbeque nation faces stiff competition\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: barbeque, nation, competition \tFEATURES: stiff     \tNEUTRAL\n",
      "\n",
      "keeps up with the competitors .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: competitors \tFEATURES: keeps     \tNEUTRAL\n",
      "\n",
      "food variety was good\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "ENTITY: food, variety \tFEATURES: good      \tPOSITIVE\n",
      "\n",
      "starters were good ! \n",
      "\n",
      "{'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.4926}\n",
      "ENTITY: starters   \tFEATURES: good      \tPOSITIVE\n",
      "\n",
      "drinks were okay . \n",
      "\n",
      "{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.2263}\n",
      "ENTITY: drinks     \tFEATURES: okay      \tPOSITIVE\n",
      "\n",
      "its barbeque nation\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: barbeque, nation \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "it goes obvious that staff was exceptional .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: staff      \tFEATURES: obvious, exceptional\tNEUTRAL\n",
      "\n",
      "we love the service . \n",
      "\n",
      "\n",
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.6369}\n",
      "ENTITY: service    \tFEATURES: love      \tPOSITIVE\n",
      "\n",
      "only issue is the ambience .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: issue, ambience \tFEATURES: only      \tNEUTRAL\n",
      "\n",
      "i feel they need to up the ambience .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: ambience   \tFEATURES: feel, need\tNEUTRAL\n",
      "\n",
      "can be better sitting arrangement\n",
      "{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}\n",
      "ENTITY: arrangement \tFEATURES: better    \tPOSITIVE\n",
      "\n",
      "better local arch .\n",
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.4404}\n",
      "ENTITY: arch       \tFEATURES: better, local\tPOSITIVE\n",
      "\n",
      "we sat at corner seat which was not comfortable\n",
      "{'neg': 0.252, 'neu': 0.748, 'pos': 0.0, 'compound': -0.4023}\n",
      "ENTITY: corner, seat \tFEATURES: comfortable\tNEGATIVE\n",
      "\n",
      "was not placed .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY:            \tFEATURES: placed    \tNEUTRAL\n",
      "\n",
      "rest enjoyed the food .\n",
      "{'neg': 0.0, 'neu': 0.476, 'pos': 0.524, 'compound': 0.5106}\n",
      "ENTITY: rest, food \tFEATURES: enjoyed   \tPOSITIVE\n",
      "\n",
      "recommended . \n",
      "\n",
      "    \n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2023}\n",
      "ENTITY:            \tFEATURES: recommended\tPOSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.032, 'neu': 0.628, 'pos': 0.34, 'compound': 0.9889}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      SPACE _SP None\n",
      "Yes INTJ UH interjection\n",
      "they PRON PRP pronoun, personal\n",
      "server VERB VBP verb, non-3rd person singular present\n",
      "really ADV RB adverb\n",
      "good ADJ JJ adjective\n",
      "food NOUN NN noun, singular or mass\n",
      "here ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "Barbeque NOUN NN noun, singular or mass\n",
      "nation NOUN NN noun, singular or mass\n",
      "faces VERB VBZ verb, 3rd person singular present\n",
      "stiff ADJ JJ adjective\n",
      "competition NOUN NN noun, singular or mass\n",
      "around ADV RB adverb\n",
      "but CCONJ CC conjunction, coordinating\n",
      "keeps VERB VBZ verb, 3rd person singular present\n",
      "up ADP RP adverb, particle\n",
      "well ADV RB adverb\n",
      "with ADP IN conjunction, subordinating or preposition\n",
      "the DET DT determiner\n",
      "competitors NOUN NNS noun, plural\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "Food NOUN NN noun, singular or mass\n",
      "variety NOUN NN noun, singular or mass\n",
      "was AUX VBD verb, past tense\n",
      "good ADJ JJ adjective\n",
      ", PUNCT , punctuation mark, comma\n",
      "starters NOUN NNS noun, plural\n",
      "were AUX VBD verb, past tense\n",
      "good ADJ JJ adjective\n",
      "! PUNCT . punctuation mark, sentence closer\n",
      "\n",
      " SPACE _SP None\n",
      "Drinks PROPN NNPS noun, proper plural\n",
      "were AUX VBD verb, past tense\n",
      "okay ADJ JJ adjective\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "\n",
      " SPACE _SP None\n",
      "Its PRON PRP$ pronoun, possessive\n",
      "Barbeque PROPN NNP noun, proper singular\n",
      "Nation PROPN NNP noun, proper singular\n",
      ", PUNCT , punctuation mark, comma\n",
      "it PRON PRP pronoun, personal\n",
      "goes VERB VBZ verb, 3rd person singular present\n",
      "obvious ADJ JJ adjective\n",
      "that SCONJ IN conjunction, subordinating or preposition\n",
      "Staff PROPN NNP noun, proper singular\n",
      "was AUX VBD verb, past tense\n",
      "exceptional ADJ JJ adjective\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "We PRON PRP pronoun, personal\n",
      "love VERB VBP verb, non-3rd person singular present\n",
      "the DET DT determiner\n",
      "Service PROPN NNP noun, proper singular\n",
      "here ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "\n",
      "\n",
      " SPACE _SP None\n",
      "Only ADJ JJ adjective\n",
      "issue NOUN NN noun, singular or mass\n",
      "is AUX VBZ verb, 3rd person singular present\n",
      "the DET DT determiner\n",
      "Ambience PROPN NNP noun, proper singular\n",
      "here ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "I PRON PRP pronoun, personal\n",
      "feel VERB VBP verb, non-3rd person singular present\n",
      "they PRON PRP pronoun, personal\n",
      "need VERB VBP verb, non-3rd person singular present\n",
      "to PART TO infinitival \"to\"\n",
      "up ADP RP adverb, particle\n",
      "the DET DT determiner\n",
      "Ambience PROPN NNP noun, proper singular\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "Can AUX MD verb, modal auxiliary\n",
      "be AUX VB verb, base form\n",
      "better ADJ JJR adjective, comparative\n",
      "sitting VERB VBG verb, gerund or present participle\n",
      "arrangement NOUN NN noun, singular or mass\n",
      "or CCONJ CC conjunction, coordinating\n",
      "better ADJ JJR adjective, comparative\n",
      "local ADJ JJ adjective\n",
      "arch NOUN NN noun, singular or mass\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "We PRON PRP pronoun, personal\n",
      "sat VERB VBD verb, past tense\n",
      "at ADP IN conjunction, subordinating or preposition\n",
      "corner NOUN NN noun, singular or mass\n",
      "seat NOUN NN noun, singular or mass\n",
      "which PRON WDT wh-determiner\n",
      "was AUX VBD verb, past tense\n",
      "not PART RB adverb\n",
      "very ADV RB adverb\n",
      "comfortable ADJ JJ adjective\n",
      "and CCONJ CC conjunction, coordinating\n",
      "was AUX VBD verb, past tense\n",
      "not PART RB adverb\n",
      "well ADV RB adverb\n",
      "placed VERB VBN verb, past participle\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "Rest NOUN NN noun, singular or mass\n",
      "enjoyed VERB VBD verb, past tense\n",
      "the DET DT determiner\n",
      "food NOUN NN noun, singular or mass\n",
      "here ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "Recommended VERB VBN verb, past participle\n",
      ". PUNCT . punctuation mark, sentence closer\n",
      "\n",
      "\n",
      "     SPACE _SP None\n"
     ]
    }
   ],
   "source": [
    "doc = sa.nlp(reviews[0])\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (\"There is so much of variety in stuffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varities NOUN NNS noun, plural\n",
      "of ADP IN conjunction, subordinating or preposition\n",
      "Veg PROPN NNP noun, proper singular\n",
      "and CCONJ CC conjunction, coordinating\n",
      "non ADJ AFX affix\n",
      "Veg PROPN NNP noun, proper singular\n",
      "foods NOUN NNS noun, plural\n",
      "was AUX VBD verb, past tense\n",
      "there ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "doc = sa.nlp (\"Varities of Veg and non Veg foods was there.\")\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Varities NOUN NNS noun, plural\n",
      "of ADP IN conjunction, subordinating or preposition\n",
      "Veg PROPN NNP noun, proper singular\n",
      "and CCONJ CC conjunction, coordinating\n",
      "non ADJ JJ adjective\n",
      "- ADJ JJ adjective\n",
      "veg ADJ JJ adjective\n",
      "foods NOUN NNS noun, plural\n",
      "was AUX VBD verb, past tense\n",
      "there ADV RB adverb\n",
      ". PUNCT . punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "r = 'Varities of Veg and non-veg foods was there.'\n",
    "print (sia.polarity_scores (r))\n",
    "\n",
    "doc = sa.nlp (r)\n",
    "for t in doc:\n",
    "    print (t, t.pos_, t.tag_, spacy.explain (t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \" First time I tried this outlet in c.p but got disappointed with their service. Marination and the taste of starters was really not good. This outlet maybe as per review stars are good just as they serve alcohol. But I will not opt this outlet as taste matters alcohol is secondary thing. Chef must see the taste and serve the food as per barbeque nation standards.I am giving 3 stars just for the hospitality of the staff which was really very good.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)\n",
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first time i tried this outlet in c.p\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: time, outlet, c.p \tFEATURES: first     \tNEUTRAL\n",
      "\n",
      "got disappointed with their service .\n",
      "{'neg': 0.437, 'neu': 0.563, 'pos': 0.0, 'compound': -0.4767}\n",
      "ENTITY: service    \tFEATURES: disappointed\tNEGATIVE\n",
      "\n",
      "marination\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: marination \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "the taste of starters was not good .\n",
      "{'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.3412}\n",
      "ENTITY: taste, starters \tFEATURES: good      \tNEGATIVE\n",
      "\n",
      "this outlet as per review stars are good as they serve alcohol .\n",
      "{'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'compound': 0.4404}\n",
      "ENTITY: outlet, review, stars, alcohol \tFEATURES: good      \tPOSITIVE\n",
      "\n",
      "i will not opt this outlet as taste matters alcohol is secondary thing .\n",
      "{'neg': 0.0, 'neu': 0.909, 'pos': 0.091, 'compound': 0.0258}\n",
      "ENTITY: outlet, taste, alcohol, thing \tFEATURES: secondary \tPOSITIVE\n",
      "\n",
      "chef must see the taste\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: chef, taste \tFEATURES: see       \tNEUTRAL\n",
      "\n",
      "serve the food as per barbeque nation standards.i am giving 3 stars for the hospitality of the staff which was good .\n",
      "{'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'compound': 0.6486}\n",
      "ENTITY: food, barbeque, nation, standards.i, stars, hospitality, staff \tFEATURES: good      \tPOSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.16, 'neu': 0.794, 'pos': 0.046, 'compound': -0.9096}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"If you are about to throw birthday parties with family and close frenzz then barbeque nation has it all. From gogappe to veg n non-veg starters to veg n non- veg main course to deserts, kulfies, gulab jamun , rasmalai everything. What else you could demand for than having served all on ur plate. All you need to do is sit back with empty tummy and enjoy each n every ounce of its food...\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)\n",
    "sa.prepare ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you are about to throw birthday parties with family\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.4019}\n",
      "ENTITY: birthday, parties, family \tFEATURES: about     \tPOSITIVE\n",
      "\n",
      "close frenzz\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: frenzz     \tFEATURES: close     \tNEUTRAL\n",
      "\n",
      "barbeque nation has it all .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: barbeque, nation \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "from gogappe to veg n non - veg starters to veg n\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: gogappe, n, starters, veg, n \tFEATURES: non, -, veg\tNEUTRAL\n",
      "\n",
      "veg main course to deserts\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: course, deserts \tFEATURES: main      \tNEUTRAL\n",
      "\n",
      "kulfies\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: kulfies    \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "gulab jamun\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: gulab, jamun \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "rasmalai everything .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: rasmalai   \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "what you could demand for than having served all on ur plate .\n",
      "{'neg': 0.12, 'neu': 0.88, 'pos': 0.0, 'compound': -0.128}\n",
      "ENTITY: ur, plate  \tFEATURES: demand, having, served\tNEGATIVE\n",
      "\n",
      "all you need to do is sit with empty tummy\n",
      "{'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'compound': -0.2023}\n",
      "ENTITY: tummy      \tFEATURES: empty     \tNEGATIVE\n",
      "\n",
      "enjoy each n\n",
      "{'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'compound': 0.4939}\n",
      "ENTITY: n          \tFEATURES: enjoy     \tPOSITIVE\n",
      "\n",
      "every ounce of its food ...\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: ounce, food \tFEATURES:           \tNEUTRAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.044, 'neu': 0.878, 'pos': 0.078, 'compound': 0.5574}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"Easily one of the worst places that I have been to in recent times.We ordered classic martini along with dahi kebabs. Their martinis were so bad we had to cancel them. Dahi kebabs had just a pea size layer of dahi in a sort of bread and alu tikki. I am sorry but that is not how you make dahi kebabs. The look and feel of the place is also quite a turn off.Would definitely advise to give this place a miss.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer (reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the worst places that i have been to in recent times.we ordered classic martini along with dahi kebabs .\n",
      "{'neg': 0.186, 'neu': 0.814, 'pos': 0.0, 'compound': -0.6249}\n",
      "ENTITY: places, martini, dahi, kebabs \tFEATURES: worst, recent, classic\tNEGATIVE\n",
      "\n",
      "their martinis were bad we had to cancel them .\n",
      "{'neg': 0.44, 'neu': 0.56, 'pos': 0.0, 'compound': -0.6705}\n",
      "ENTITY: martinis   \tFEATURES: bad       \tNEGATIVE\n",
      "\n",
      "dahi kebabs had a pea size layer of dahi in a sort of bread\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: dahi, kebabs, pea, size, layer, dahi, sort, bread \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "alu tikki .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: alu, tikki \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "i am sorry\n",
      "{'neg': 0.565, 'neu': 0.435, 'pos': 0.0, 'compound': -0.0772}\n",
      "ENTITY:            \tFEATURES: sorry     \tNEGATIVE\n",
      "\n",
      "that is not you make dahi kebabs .\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: dahi, kebabs \tFEATURES: make      \tNEUTRAL\n",
      "\n",
      "the look\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: look       \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "feel of the place is quite a turn advise to give this place a miss .\n",
      "{'neg': 0.118, 'neu': 0.882, 'pos': 0.0, 'compound': -0.1531}\n",
      "ENTITY: feel, place, turn, place, miss \tFEATURES: advise, give\tNEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (\"that is not how you make dahi kababs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores (\"You do not how to cook food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sia.polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'compound': -0.4939}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x('The servers overthere are fools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.524, 'neu': 0.476, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"The waiters were idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.352, 'neu': 0.519, 'pos': 0.13, 'compound': -0.6124}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"I like the benetton tshirts but their pants are bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.196, 'neu': 0.522, 'pos': 0.283, 'compound': 0.25}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x (\"Benetton tshirts are bad but i like their pants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [ \"I like the benetton tshirts but their pants were not okay\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like the benetton tshirts\n",
      "{'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.3612}\n",
      "ENTITY: benetton, tshirts \tFEATURES: like      \tPOSITIVE\n",
      "\n",
      "their pants were not okay\n",
      "{'neg': 0.294, 'neu': 0.706, 'pos': 0.0, 'compound': -0.1695}\n",
      "ENTITY: pants      \tFEATURES: okay      \tNEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer(r)\n",
    "sa.prepare()\n",
    "counter = 0\n",
    "for split in sa.splits:\n",
    "    sent = ' '.join (map(str, split))\n",
    "    print (sent)\n",
    "    scores = sia.polarity_scores (sent)\n",
    "    print (scores)\n",
    "    print (f\"ENTITY: {sa.features[counter][0]:<10} \\tFEATURES: {sa.features[counter][1]:<10}\", end=\"\\t\")\n",
    "    if scores['compound'] > 0:\n",
    "        print (\"POSITIVE\")\n",
    "    elif scores['compound'] == 0:\n",
    "        print (\"NEUTRAL\")\n",
    "    else:\n",
    "        print (\"NEGATIVE\");\n",
    "    counter += 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 95 PRON 13656873538139661788 PRP\n",
      "am 87 AUX 9188597074677201817 VBP\n",
      "balor.i 92 NOUN 783433942507015291 NNS\n",
      "am 87 AUX 9188597074677201817 VBP\n",
      "Anshuman 96 PROPN 15794550382381185553 NNP\n"
     ]
    }
   ],
   "source": [
    "doc = sa.nlp (\"i am balor.i am Anshuman\")\n",
    "for t in doc:\n",
    "    print (t, t.pos, t.pos_, t.tag, t.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[i am balor.i am Anshuman]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[i, am, balor.i, am, anshuman]]\n",
      "i am balor.i am anshuman\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ENTITY: balor.i, anshuman \tFEATURES:           \tNEUTRAL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer(['i am balor.i am Anshuman'])\n",
    "sa.prepare()\n",
    "print (sa.splits)\n",
    "sa.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'reviews'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-97d23518153d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"I am going home.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'reviews'"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer()\n",
    "doc = sa.nlp (\"I am going home.\")\n",
    "for token in doc:\n",
    "    print (token, token.pos, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
